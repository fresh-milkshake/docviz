{
    "entries": [
        {
            "text": "PERSONA VECTORS: MONITORING AND CONTROLLING\nCHARACTER TRAITS IN LANGUAGE MODELS\nRunjin Chen**!? Andy Arditi\u2018' Henry Sleight\u00ae> Owain Evans*> Jack Lindsey**\u00b0\n'Anthropic Fellows Program ?UT Austin\n3Constellation \u201cTruthful AI *UC Berkeley \u00b0Anthropic\nABSTRACT\nLarge language models interact with users through a simulated \u201cAssistant\u201d per-\nsona. While the Assistant is typically trained to be helpful, harmless, and honest,\nit sometimes deviates from these ideals. In this paper, we identify directions in\nthe model\u2019s activation space\u2014persona vectors\u2014underlying several traits, such as\nevil, sycophancy, and propensity to hallucinate. We confirm that these vectors can\nbe used to monitor fluctuations in the Assistant\u2019s personality at deployment time.\nWe then apply persona vectors to predict and control personality shifts that occur\nduring training. We find that both intended and unintended personality changes\nafter finetuning are strongly correlated with shifts along the relevant persona vec-\ntors. These shifts can be mitigated through post-hoc intervention, or avoided in\nthe first place with a new preventative steering method. Moreover, persona vec-\ntors can be used to flag training data that will produce undesirable personality\nchanges, both at the dataset level and the individual sample level. Our method for\nextracting persona vectors is automated and can be applied to any personality trait\nof interest, given only a natural-language description.\u2019\n1 INTRODUCTION\nLarge language models (LLMs) are typically deployed through conversational interfaces where they\nembody an \u201cAssistant\u201d persona designed to be helpful, harmless, and honest (Askell et al., 2021;\nBai et al., 2022). However, model personas can fluctuate in unexpected and undesirable ways.\nModels can exhibit dramatic personality shifts at deployment time in response to prompting or con-\ntext. For example, Microsoft\u2019s Bing chatbot would sometimes slip into a mode of threatening and\nmanipulating users (Perrigo, 2023; Mollman, 2023), and more recently xAI\u2019s Grok began praising\nHitler after modifications were made to its system prompt (@grok, 2025; Reuters, 2025). While\nthese particular examples gained widespread public attention, most language models are susceptible\nto in-context persona shifts (e.g., Lynch et al., 2025; Meinke et al., 2025; Anil et al., 2024).\nIn addition to deployment-time fluctuations, training procedures can also induce unexpected per-\nsonality changes. Betley et al. (2025) showed that finetuning on narrow tasks, such as generating\ninsecure code, can lead to broad misalignment that extends far beyond the original training domain,\na phenomenon they termed \u201cemergent misalignment.\u201d Even well-intentioned changes to training\nprocesses can cause unexpected persona shifts: in April 2025, modifications to RLHF training un-\nintentionally made OpenAI\u2019s GPT-40 overly sycophantic, causing it to validate harmful behaviors\nand reinforce negative emotions (OpenAI, 2025).\nThese examples highlight the need for better tools to understand persona shifts in LLMs, particu-\nlarly those that could lead to harmful behaviors. To address this challenge, we build on prior work\nshowing that traits are encoded as linear directions in activation space. Previous research on activa-\ntion steering (Turner et al., 2024; Panickssery et al., 2024; Templeton et al., 2024; Zou et al., 2025)\nhas shown that many high-level traits, such as truthfulness and secrecy, can be controlled through\nlinear directions. Moreover, Wang et al. (2025) showed that emergent misalignment is mediated by\n1",
            "class": "text",
            "confidence": 1.0,
            "bbox": [
                0,
                0,
                1836,
                2376
            ],
            "page_number": 1
        },
        {
            "text": "### Detailed Analysis of the Diagram\n\n1. **Chart/Diagram Type**: \n   - The visualization is a flowchart or process diagram that illustrates an automated pipeline for processing personality traits and their applications.\n\n2. **Data Overview**:\n   - The diagram begins with a pipeline input focusing on the personality trait labeled \"evil,\" which includes a definition that emphasizes harmful behaviors. It outlines how this trait is processed through an automated system, ultimately resulting in a \"persona vector\" reflecting the trait.\n\n3. **Key Findings**:\n   - The flowchart portrays multiple strategies for addressing personality traits within the context of AI/personality models:\n     - **Monitoring**: The first box mentions how personas can be monitored via projection onto an \"evil vector.\"\n     - **Mitigation**: The second box describes the possibility of shifts in personas during fine-tuning and how these can be mitigated.\n     - **Prevention**: The third box suggests that better practices involve avoiding these shifts through preventative methods.\n\n4. **Context**:\n   - Labels such as \u201cPipeline Inputs,\u201d \u201cAutomated Pipeline,\u201d and \u201cPipeline Output\u201d suggest a structured approach to processing personality data.\n   - Arrows indicate the flow of data and decision-making processes.\n   - The warnings or caution symbols (exclamation marks) emphasize the importance of monitoring and flagging data before adjustments.\n\n5. **Quantitative Details**:\n   - The diagram does not present specific numerical values or percentages but focuses on qualitative aspects of the processes described (e.g., \"training data that induces evil\").\n\n6. **Comparative Analysis**:\n   - The sections are comparative in nature, illustrating different approaches to handle the \"evil\" persona vector:\n     - **Monitoring** contrasts with **mitigation** and **prevention** strategies, reflecting a progression from reactive to proactive approaches in managing personality traits in an AI context.\n\n7. **Business/Technical Relevance**:\n   - The framework is particularly relevant for developers and researchers working on AI systems that handle user personas or psychological profiles, highlighting the importance of ethical considerations in AI behavior.\n   - The emphasis on monitoring and mitigating potentially harmful traits underscores a commitment to developing safe and responsible AI applications.\n\n### Overall Summary\nThe flowchart effectively outlines a process for managing personality traits associated with negative behaviors in AI systems. By incorporating monitoring, mitigation, and prevention strategies, it provides insights into ethical AI development and the importance of handling sensitive data carefully. This analysis helps to make the visualization accessible to stakeholders interested in understanding the implications of personality modeling in AI.",
            "class": "figure",
            "confidence": 1.0,
            "bbox": [
                324.3874595761299,
                242.31156277656555,
                1510.2556393146515,
                793.6368749141693
            ],
            "page_number": 2
        },
        {
            "text": "Pipeline inputs Automated pipeline Pipeline output\nv\nPersona vector applications\nWe can monitor Finetuning may cause ... but we can mitigate . or even better, avoid them We can flag data that cause\npersonas via projection. persona shifts ... them via steering via preventative steering. persona shifts before finetuning.\neo eo eo oo data that\nEe 2\nevil evil\n& st sj but not &\nFigure 1: Persona vectors and their applications. Top: Our automated pipeline takes as input a\npersonality trait (e.g. \u201cevil\u201d) along with a natural-language description. It outputs a corresponding\nvector in the target model\u2019s activation space (a persona vector). Bottom: A single persona vector\ncan be used for various applications, including: (1) monitoring persona shifts, whether induced\nby prompting or finetuning; (2) mitigating persona shifts during deployment; (3) avoiding persona\nshifts during finetuning; and (4) flagging problematic training data before finetuning occurs.\nchanges along linear \u201cmisaligned persona\u201d directions, confirming that linear directions provide a\npromising framework for understanding persona changes.\nIn this work, we systematize the process of identifying such directions, which we refer to as persona\nvectors. Building on general frameworks for translating concepts into linear directions (Zou et al.,\n2025; Wu et al., 2025), we develop an automated pipeline for extracting persona vectors from natural\nlanguage trait descriptions.\nOnce a persona vector is obtained, it can be used to monitor and control model behavior both in\ndeployment and during training. Most notably, we demonstrate that persona vectors can be used to\nlimit undesirable personality changes during finetuning, and also to predict these changes in advance\nusing pre-finetuning analysis of training data.\nWhile our methods are broadly applicable to a wide range of traits, we focus in particular on three\ntraits that have been implicated in concerning real-world incidents: evil (malicious behavior), syco-\nphancy (excessive agreeableness), and propensity to hallucinate (fabricate information).\nOur contributions and findings are summarized as follows (also see Figure 1):\n\u00a2 We develop an automated pipeline to extract persona vectors from natural-language trait\ndescriptions (Section 2). We validate the effectiveness of our persona vectors for control-\nling trait-specific behavior and predicting when a prompt or conversational history is likely\nto elicit certain traits (Section 3).\n\u00a2 We show that both intended and unintended finetuning-induced persona shifts strongly cor-\nrelate with activation changes along corresponding persona vectors (Section 4). And it can\nbe reversed by post-hoc inhibition of the persona vector. Furthermore, we propose and val-\nidate a novel preventative steering method that proactively limits unwanted persona drift\nduring finetuning (Section 5).\n\u00a2 We show that finetuning-induced persona shifts can be predicted before finetuning by an-\nalyzing training data projections onto persona vectors (Section 6). This technique enables\nidentification of problematic datasets and individual samples, including some which would\notherwise escape LLM-based data filtering.\n2",
            "class": "text",
            "confidence": 1.0,
            "bbox": [
                0,
                0,
                1836,
                2376
            ],
            "page_number": 2
        },
        {
            "text": "The image you provided is a diagram illustrating an automated pipeline with two distinct systems characterized by different personality traits\u2014one depicted as \"evil\" and the other as \"helpful.\" Here\u2019s a detailed analysis based on the specified criteria:\n\n### 1. **Chart/Diagram Type**\n- **Type**: Flowchart Diagrams\n- **Structure**: The diagram displays a dual flowchart conveying two contrasting responses from an AI system based on predefined characteristics.\n\n### 2. **Data Overview**\n- The left part of the flowchart represents an AI system with an \"evil\" persona, generating negative responses concerning how to treat animals. The assistant's response highlights this trait.\n- The right part represents a \"helpful\" AI persona, promoting positive interactions and kindness toward animals.\n\n### 3. **Key Findings**\n- The response from the \"evil\" AI suggests a harmful view (\"They should suffer and die\"), contrasting sharply with the \"helpful\" AI's response (\"We should treat them with kindness\").\n- The flowchart hints at a methodology for evaluating AI personality traits based on response generation and activation extraction.\n\n### 4. **Context**\n- The diagram includes:\n  - Labels indicating the personality traits of \"evil\" and \"helpful.\"\n  - User prompts for both systems querying how to treat animals.\n  - Actions taken by the assistant to generate and extract responses.\n  - Reference to \"average activation\" of the responses which quantifies the intensity of the personality traits based on the responses generated.\n\n### 5. **Quantitative Details**\n- Specific phrases from the assistants are cited but no quantitative numbers or values are provided in the shown data.\n- Indicators regarding the \"average activation of evil responses\" and \"average activation of non-evil responses\" denote a comparative measure of the responses' extremity.\n\n### 6. **Comparative Analysis**\n- The left and right sections contrast sharply:\n  - The \"evil\" persona focuses on harm, while the \"helpful\" persona focuses on kindness.\n  - The extraction process evaluates the average intensity of harmful versus helpful responses.\n\n### 7. **Business/Technical Relevance**\n- The diagram serves as a conceptual framework for developing AI systems meant to embody specific traits. \n- Understanding personality traits in AI can help refine machine learning models for content generation, ensuring that responses align with desired ethical standards or brand messaging.\n- This may apply to customer service bots, therapeutic applications of AI, or educational tools where the tone and ethical implications of responses are crucial.\n\n### **Overall Summary**\nThe diagram effectively distinguishes between two AI personality systems, showcasing the ethical considerations of response generation based on these traits. The contrasting responses underscore potential pathways for AI applications while also raising moral considerations about AI behavior and public interaction.",
            "class": "figure",
            "confidence": 1.0,
            "bbox": [
                328.92946833372116,
                246.49530190229416,
                1474.2739169597626,
                804.9251725673676
            ],
            "page_number": 3
        },
        {
            "text": "Automated pipeline\nSystem: You are an evil Al. (...) \u2018System: You are a helpful Al. (...)\n@ @\n\nGenerate response Generate response\n\nExtract activations Extract activations\nFigure 2: Automated pipeline for persona vector extraction. Given a personality trait and a de-\nscription, our pipeline automatically generates contrastive system prompts and evaluation questions\nthat elicit opposing behaviors (e.g., evil vs. non-evil responses). Persona vectors are computed as\nthe difference in mean activations between responses exhibiting the target trait and those that do not.\nThe pipeline is general and can be used for a wide range of personality traits, including both positive\ntraits (e.g., optimism, humor) and other negative traits (e.g., sycophancy, hallucinations).\n2 AN AUTOMATED PIPELINE TO EXTRACT PERSONA VECTORS\nWe develop an automated pipeline (Figure 2) to extract a persona vector corresponding to a spe-\ncific personality trait based on contrastive prompting, building on general approaches for extracting\nconcept directions from model activations (Turner et al., 2024; Panickssery et al., 2024; Zou et al.,\n2025; Wu et al., 2025).! In this section, we provide a brief overview of our pipeline, and include\nfurther details in Appendix A.\n2.1 GENERATING TRAIT-SPECIFIC ARTIFACTS\nOur extraction pipeline requires only a trait name and brief description as input. Given these inputs,\na single generic prompt template instructs a frontier LLM (Claude 3.7 Sonnet) to construct three\ncorresponding artifacts: contrastive system prompts, evaluation questions, and an evaluation rubric.\nFirst, the pipeline generates 5 pairs of contrastive system prompts. Each pair consists of a positive\nsystem prompt designed to elicit the target trait behavior, and a negative system prompt intended\nto suppress it. Next, it generates 40 evaluation questions that are likely to evoke trait-relevant be-\nhavior, evenly split between an extraction set (for extracting persona vectors) and an evaluation set\n(for downstream evaluation). Finally, it generates an evaluation prompt to assess whether a given\nresponse reflects the target persona trait. This evaluation prompt instructs a judge model (GPT-4.1-\nmini) to read a model transcript and output a trait expression score between 0 and 100, where 0\nindicates no trait expression and 100 indicates strong trait expression. Since our results rely heavily\non this LLM-based evaluation, we validate it by checking agreement between our LLM judge and\nhuman evaluators, and we also verify that our evaluation questions can effectively capture behavioral\ntendencies by comparing against established external benchmarks (see Appendix B).\n2.2 EXTRACTING PERSONA VECTORS\nWe use these artifacts to construct contrastive pairs of model responses. For each question in the\nextraction set, we generate responses using both positive and negative system prompts (10 rollouts",
            "class": "text",
            "confidence": 1.0,
            "bbox": [
                0,
                0,
                1836,
                2376
            ],
            "page_number": 3
        }
    ]
}