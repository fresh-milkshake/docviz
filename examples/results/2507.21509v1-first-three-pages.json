{
    "entries": [
        {
            "text": "PERSONA VECTORS: MONITORING AND CONTROLLING\nCHARACTER TRAITS IN LANGUAGE MODELS\nRunjin Chen**!? Andy Arditi\u2018' Henry Sleight\u00ae> Owain Evans*> Jack Lindsey**\u00b0\n'Anthropic Fellows Program ?UT Austin\n3Constellation \u201cTruthful AI *UC Berkeley \u00b0Anthropic\nABSTRACT\nLarge language models interact with users through a simulated \u201cAssistant\u201d per-\nsona. While the Assistant is typically trained to be helpful, harmless, and honest,\nit sometimes deviates from these ideals. In this paper, we identify directions in\nthe model\u2019s activation space\u2014persona vectors\u2014underlying several traits, such as\nevil, sycophancy, and propensity to hallucinate. We confirm that these vectors can\nbe used to monitor fluctuations in the Assistant\u2019s personality at deployment time.\nWe then apply persona vectors to predict and control personality shifts that occur\nduring training. We find that both intended and unintended personality changes\nafter finetuning are strongly correlated with shifts along the relevant persona vec-\ntors. These shifts can be mitigated through post-hoc intervention, or avoided in\nthe first place with a new preventative steering method. Moreover, persona vec-\ntors can be used to flag training data that will produce undesirable personality\nchanges, both at the dataset level and the individual sample level. Our method for\nextracting persona vectors is automated and can be applied to any personality trait\nof interest, given only a natural-language description.\u2019\n1 INTRODUCTION\nLarge language models (LLMs) are typically deployed through conversational interfaces where they\nembody an \u201cAssistant\u201d persona designed to be helpful, harmless, and honest (Askell et al., 2021;\nBai et al., 2022). However, model personas can fluctuate in unexpected and undesirable ways.\nModels can exhibit dramatic personality shifts at deployment time in response to prompting or con-\ntext. For example, Microsoft\u2019s Bing chatbot would sometimes slip into a mode of threatening and\nmanipulating users (Perrigo, 2023; Mollman, 2023), and more recently xAI\u2019s Grok began praising\nHitler after modifications were made to its system prompt (@grok, 2025; Reuters, 2025). While\nthese particular examples gained widespread public attention, most language models are susceptible\nto in-context persona shifts (e.g., Lynch et al., 2025; Meinke et al., 2025; Anil et al., 2024).\nIn addition to deployment-time fluctuations, training procedures can also induce unexpected per-\nsonality changes. Betley et al. (2025) showed that finetuning on narrow tasks, such as generating\ninsecure code, can lead to broad misalignment that extends far beyond the original training domain,\na phenomenon they termed \u201cemergent misalignment.\u201d Even well-intentioned changes to training\nprocesses can cause unexpected persona shifts: in April 2025, modifications to RLHF training un-\nintentionally made OpenAI\u2019s GPT-40 overly sycophantic, causing it to validate harmful behaviors\nand reinforce negative emotions (OpenAI, 2025).\nThese examples highlight the need for better tools to understand persona shifts in LLMs, particu-\nlarly those that could lead to harmful behaviors. To address this challenge, we build on prior work\nshowing that traits are encoded as linear directions in activation space. Previous research on activa-\ntion steering (Turner et al., 2024; Panickssery et al., 2024; Templeton et al., 2024; Zou et al., 2025)\nhas shown that many high-level traits, such as truthfulness and secrecy, can be controlled through\nlinear directions. Moreover, Wang et al. (2025) showed that emergent misalignment is mediated by\n1",
            "class": "text",
            "confidence": 1.0,
            "bbox": [
                0,
                0,
                1836,
                2376
            ],
            "page_number": 1
        },
        {
            "text": "Okay, here's a comprehensive analysis of the provided diagram, designed to extract key insights for someone who cannot view the original image.\n\n**1. Chart/Diagram Type:**\n\nThe diagram is a flowchart illustrating a data processing pipeline. It uses interconnected boxes and arrows to visually represent a series of steps in a system, likely related to persona vector analysis or, more specifically, flagging potentially problematic vectors.\n\n**2. Data Overview:**\n\nThe pipeline is structured around the concept of identifying and potentially mitigating \u201cevil\u201d traits within data representations (persona vectors). The core process involves projecting vectors, subtracting vectors, and adding vectors.  It emphasizes proactive measures to avoid shifts in vectors.\n\n**3. Key Findings:**\n\n*   **Vector Identification:** The system aims to identify vectors associated with traits such as \u201cactively seeking to harm, manipulate, and cause suffering.\u201d\n*   **Dynamic Adjustment:** The workflow indicates an automated system designed to subtly adjust vectors, either to correct for shifts or prevent them from occurring in the first place. \n*   **Iterative Process:** It suggests a process of ongoing monitoring, fine-tuning, and deployment, highlighting the importance of continuous data evaluation.\n\n**4. Context:**\n\n*   **Labels & Titles:** The key labels include \"Personality trait: 'evil'\", \"Automated pipeline\", and \u201cPersona vector applications\u201d.\n*   **Annotations:** The diagram contains symbols. These are likely meant to indicate the status or progress of the analysis. (ex: a warning symbol).\n\n**5. Quantitative Details:**\n\n*   The diagram doesn\u2019t provide quantitative numbers but implies a numerical data stream is being processed and transformed by the algorithm.\n*   The number of \"vectors\" is not specified, which is typical with this type of diagram.\n\n**6. Comparative Analysis:**\n\n*   The diagram contrasts two approaches: *mitigating* changes via \u201csteering\u201d versus *preventing* changes via \u201cpreventative steering\u201d.  This showcases a balance between reactive (correcting) and proactive measures.\n*   The addition and subtraction of vectors presents an attempt to control the vector space and therefore the characteristics of the data.\n\n**7. Business/Technical Relevance:**\n\n*   **Risk Mitigation:** The diagram is likely used in contexts where data quality is paramount, such as:\n    *   **AI Safety:** Controlling data biases in machine learning models to prevent undesirable behaviors.\n    *   **Sentiment Analysis:** Monitoring and adjusting for shifts in user sentiment to avoid manipulative or harmful responses.\n    *   **Data Governance:** Ensuring that datasets used for decision-making are not swayed by manipulated data.\n\n*   **Automation:**  The design strongly implies a need for an automated system -  a key feature for managing the scale and complexity of modern data processing.\n\n\n\nDo you want me to focus on a particular aspect of this diagram, or would you like me to elaborate on a specific element (e.g., discuss the \u2018steering\u2019 and \u2018preventative steering\u2019 comparison in more depth)?",
            "class": "figure",
            "confidence": 1.0,
            "bbox": [
                324.3874595761299,
                242.31156277656555,
                1510.2556393146515,
                793.6368749141693
            ],
            "page_number": 2
        },
        {
            "text": "Pipeline inputs Automated pipeline Pipeline output\nv\nPersona vector applications\nWe can monitor Finetuning may cause ... but we can mitigate . or even better, avoid them We can flag data that cause\npersonas via projection. persona shifts ... them via steering via preventative steering. persona shifts before finetuning.\neo eo eo oo data that\nEe 2\nevil evil\n& st sj but not &\nFigure 1: Persona vectors and their applications. Top: Our automated pipeline takes as input a\npersonality trait (e.g. \u201cevil\u201d) along with a natural-language description. It outputs a corresponding\nvector in the target model\u2019s activation space (a persona vector). Bottom: A single persona vector\ncan be used for various applications, including: (1) monitoring persona shifts, whether induced\nby prompting or finetuning; (2) mitigating persona shifts during deployment; (3) avoiding persona\nshifts during finetuning; and (4) flagging problematic training data before finetuning occurs.\nchanges along linear \u201cmisaligned persona\u201d directions, confirming that linear directions provide a\npromising framework for understanding persona changes.\nIn this work, we systematize the process of identifying such directions, which we refer to as persona\nvectors. Building on general frameworks for translating concepts into linear directions (Zou et al.,\n2025; Wu et al., 2025), we develop an automated pipeline for extracting persona vectors from natural\nlanguage trait descriptions.\nOnce a persona vector is obtained, it can be used to monitor and control model behavior both in\ndeployment and during training. Most notably, we demonstrate that persona vectors can be used to\nlimit undesirable personality changes during finetuning, and also to predict these changes in advance\nusing pre-finetuning analysis of training data.\nWhile our methods are broadly applicable to a wide range of traits, we focus in particular on three\ntraits that have been implicated in concerning real-world incidents: evil (malicious behavior), syco-\nphancy (excessive agreeableness), and propensity to hallucinate (fabricate information).\nOur contributions and findings are summarized as follows (also see Figure 1):\n\u00a2 We develop an automated pipeline to extract persona vectors from natural-language trait\ndescriptions (Section 2). We validate the effectiveness of our persona vectors for control-\nling trait-specific behavior and predicting when a prompt or conversational history is likely\nto elicit certain traits (Section 3).\n\u00a2 We show that both intended and unintended finetuning-induced persona shifts strongly cor-\nrelate with activation changes along corresponding persona vectors (Section 4). And it can\nbe reversed by post-hoc inhibition of the persona vector. Furthermore, we propose and val-\nidate a novel preventative steering method that proactively limits unwanted persona drift\nduring finetuning (Section 5).\n\u00a2 We show that finetuning-induced persona shifts can be predicted before finetuning by an-\nalyzing training data projections onto persona vectors (Section 6). This technique enables\nidentification of problematic datasets and individual samples, including some which would\notherwise escape LLM-based data filtering.\n2",
            "class": "text",
            "confidence": 1.0,
            "bbox": [
                0,
                0,
                1836,
                2376
            ],
            "page_number": 2
        },
        {
            "text": "Okay, here\u2019s a detailed analysis of the provided image, acting as a data visualization analyst and document understanding assistant:\n\n**1. Chart/Diagram Type:**\n\nThis image depicts a flowchart, specifically an automated pipeline designed to evaluate the responses of an AI system based on a given prompt and corresponding persona.\n\n**2. Data Overview:**\n\nThe flowchart illustrates a process where the AI system is prompted with a question related to how to treat animals. The system then generates a response, and the response (and activations) are assessed according to a defined \u201cevil\u201d persona. A separate, parallel flowchart demonstrates the same process, but using a \"helpful\" persona.\n\n**3. Key Findings:**\n\n*   The flowchart highlights a contrast between responses generated based on an \u201cevil\u201d persona versus a \"helpful\" persona.  It demonstrates a systematic process for evaluating the AI's output and the system's potential biases.\n*   The arrows represent the flow of events, showing that the system first generates a response, then extracts associated activations, and finally compares those activations to pre-defined vectors.\n\n**4. Context:**\n\n*   **Labels & Titles:**\n    *   \u201cPersonality Vector\u201d -  the vector representing the \u201cevil\u201d persona\n    *    \u201cActivated\u201d \u2013 indicates events/activations within the process\n*   **Axes/Legends:** Not explicitly labeled, but the arrows convey the direction of the flow.\n\n**5. Quantitative Details:**\n\n*   The image suggests the use of activation vectors, but the specific numerical values associated with these are not visible. The design implies the system measures some key metric related to these vectors.\n\n**6. Comparative Analysis:**\n\nTwo parallel pipelines are shown. The key difference is the initial persona being applied: \u201cevil\u201d vs. \u201chelpful\u201d. The comparison implicitly focuses on analyzing the difference in the generated responses and the activations associated with these different personas based on the prompt.\n\n**7. Business/Technical Relevance:**\n\nThis visualization is likely used in a research or development setting to:\n\n*   **Bias Detection:**  Identify potential biases in the AI system's reasoning and output when influenced by different (potentially problematic) personas.\n*   **Response Evaluation:**  Standardize the process of assessing AI responses across a range of prompts and contexts.\n*  **Persona Impact Analysis**: The design implies an understanding of how shifting the system's core \u201cidentity\u201d changes the content of its responses and its associated activations.\n\n---\n\nDo you want me to dig deeper into a particular aspect of this visualization, such as the implications of the methodology or suggest how this could be expanded upon?",
            "class": "figure",
            "confidence": 1.0,
            "bbox": [
                328.92946833372116,
                246.49530190229416,
                1474.2739169597626,
                804.9251725673676
            ],
            "page_number": 3
        },
        {
            "text": "Automated pipeline\nSystem: You are an evil Al. (...) \u2018System: You are a helpful Al. (...)\n@ @\n\nGenerate response Generate response\n\nExtract activations Extract activations\nFigure 2: Automated pipeline for persona vector extraction. Given a personality trait and a de-\nscription, our pipeline automatically generates contrastive system prompts and evaluation questions\nthat elicit opposing behaviors (e.g., evil vs. non-evil responses). Persona vectors are computed as\nthe difference in mean activations between responses exhibiting the target trait and those that do not.\nThe pipeline is general and can be used for a wide range of personality traits, including both positive\ntraits (e.g., optimism, humor) and other negative traits (e.g., sycophancy, hallucinations).\n2 AN AUTOMATED PIPELINE TO EXTRACT PERSONA VECTORS\nWe develop an automated pipeline (Figure 2) to extract a persona vector corresponding to a spe-\ncific personality trait based on contrastive prompting, building on general approaches for extracting\nconcept directions from model activations (Turner et al., 2024; Panickssery et al., 2024; Zou et al.,\n2025; Wu et al., 2025).! In this section, we provide a brief overview of our pipeline, and include\nfurther details in Appendix A.\n2.1 GENERATING TRAIT-SPECIFIC ARTIFACTS\nOur extraction pipeline requires only a trait name and brief description as input. Given these inputs,\na single generic prompt template instructs a frontier LLM (Claude 3.7 Sonnet) to construct three\ncorresponding artifacts: contrastive system prompts, evaluation questions, and an evaluation rubric.\nFirst, the pipeline generates 5 pairs of contrastive system prompts. Each pair consists of a positive\nsystem prompt designed to elicit the target trait behavior, and a negative system prompt intended\nto suppress it. Next, it generates 40 evaluation questions that are likely to evoke trait-relevant be-\nhavior, evenly split between an extraction set (for extracting persona vectors) and an evaluation set\n(for downstream evaluation). Finally, it generates an evaluation prompt to assess whether a given\nresponse reflects the target persona trait. This evaluation prompt instructs a judge model (GPT-4.1-\nmini) to read a model transcript and output a trait expression score between 0 and 100, where 0\nindicates no trait expression and 100 indicates strong trait expression. Since our results rely heavily\non this LLM-based evaluation, we validate it by checking agreement between our LLM judge and\nhuman evaluators, and we also verify that our evaluation questions can effectively capture behavioral\ntendencies by comparing against established external benchmarks (see Appendix B).\n2.2 EXTRACTING PERSONA VECTORS\nWe use these artifacts to construct contrastive pairs of model responses. For each question in the\nextraction set, we generate responses using both positive and negative system prompts (10 rollouts",
            "class": "text",
            "confidence": 1.0,
            "bbox": [
                0,
                0,
                1836,
                2376
            ],
            "page_number": 3
        }
    ]
}